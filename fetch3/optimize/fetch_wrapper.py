"""
Optimization wrapper for FETCH3.

These functions provide the interface between the optimization tool and FETCH3
- Setting up optimization experiment
- Creating directories for model outputs of each iteration
- Writing model configuration files for each iteration
- Starting model runs for each iteration
- Reading model outputs and observation data for model evaluation
- Defines objective function for optimization, and other performance metrics of interest
- Defines how results of each iteration should be evaluated
"""

import atexit
import datetime as dt
import os
import subprocess
from pathlib import Path

import numpy as np
import pandas as pd
import xarray as xr
import yaml
from ax import Trial
from boa import (
    BaseWrapper,
    cd_and_cd_back,
    get_trial_dir,
    make_trial_dir,
    write_configs,
)

from fetch3.scaling import convert_trans_m3s_to_cm3hr


def read_experiment_config(config_file):
    """
    Read experiment configuration yml file for setting up the optimization.
    yml file contains the list of parameters, and whether each parameter is a fixed
    parameter or a range parameter. Fixed parameters have a value specified, and range
    parameters have a range specified.

    Parameters
    ----------
    config_file : str
        File path for the experiment configuration file

    Returns
    -------
    params: list
        Parameters formatted for the Ax experiment
    experiment_settings: dict
        Optimization options for the experiment
    """

    # Load the experiment config yml file
    with open(config_file, "r") as yml_config:
        loaded_configs = yaml.safe_load(yml_config)

    # Format parameters for Ax experiment
    for param in loaded_configs["parameters"].keys():
        # Add "name" attribute for each parameter
        loaded_configs["parameters"][param]["name"] = param
    # Parameters from dictionary to list
    params = [loaded_configs["parameters"][param] for param in list(loaded_configs["parameters"])]
    experiment_settings = loaded_configs["optimization_options"]
    model_settings = loaded_configs["model_options"]
    return params, experiment_settings, model_settings


def create_experiment_dir(working_dir, ax_client):
    """
    Creates directory for the experiment and returns the path.
    The directory is named with the experiment name and the current datetime.

    Parameters
    ----------
    working_dir : str
        Working directory, the parent directory where the experiment directory will be written
    ax_client : Ax client
        Initialized Ax client for the experiment

    Returns
    -------
    Path
        Path to the directory for the experiment
    """
    # Directory named with experiment name and datetime
    ex_dir = Path(working_dir) / (
        ax_client.experiment.name + "_" + dt.datetime.now().strftime("%Y%m%dT%H%M%S")
    )
    ex_dir.mkdir()
    return ex_dir


def create_trial_dir(experiment_dir, trial_index):
    """
    Create a directory for a trial, and return the path to the directory.
    Trial directory is created inside the experiment directory, and named with the trial index.
    Model configs and outputs for each trial will be written here.

    Parameters
    ----------
    experiment_dir : Path
        Directory for the experiment
    trial_index : int
        Trial index from the Ax client

    Returns
    -------
    Path
        Directory for the trial
    """
    trial_dir = experiment_dir / str(trial_index).zfill(6)  # zero-padded trial index
    trial_dir.mkdir()
    return trial_dir


def write_configs(trial_dir, parameters, model_options):
    """
    Write model configuration file for each trial (model run). This is the config file used by FETCH3
    for the model run.

    The config file is written as ```config.yml``` inside the trial directory.

    Parameters
    ----------
    trial_dir : Path
        Trial directory where the config file will be written
    parameters : list
        Model parameters for the trial, generated by the ax client
    model_options : dict
        Model options loaded from the experiment config yml file.

    Returns
    -------
    str
        Path for the config file
    """
    with open(trial_dir / "config.yml", "w") as f:
        # Write model options from loaded config
        # Parameters for the trial from Ax
        config_dict = {"model_options": model_options, "parameters": parameters}
        yaml.dump(config_dict, f)
        return f.name


def get_model_obs(modelfile, obsfile, ex_settings, model_settings, parameters):
    """
    Read in observation data model output for a trial, which will be used for
    calculating the objective function for the trial.

    Parameters
    ----------
    modelfile : str
        File path to the model output
    obsfile : str
        File path to the observation data
    model_settings: dict
        dictionary with model settings read from model config file

    Returns
    -------
    model_output: pandas Series
        Model output
    obs: pandas Series
        Observations

    ..todo::
        * Add options to specify certain variables from the observation/output files
        * Add option to read from .nc file

    """
    # Read config file

    # Read in observation data
    obsdf = pd.read_csv(obsfile, parse_dates=[0])
    # Converting time since sapfluxnet data is in GMT
    obsdf["Timestamp"] = obsdf.TIMESTAMP.dt.tz_convert("EST")
    obsdf = obsdf.set_index("Timestamp")

    # Read in model output
    modeldf = xr.load_dataset(modelfile)

    # Slice met data to just the time period that was modeled
    obsdf = obsdf.loc[modeldf.time.data[0] : modeldf.time.data[-1]]

    # Convert model output to the same units as the input data
    # Sapfluxnet data is in cm3 hr-1
    modeldf["sapflux_scaled"] = convert_trans_m3s_to_cm3hr(modeldf.sapflux)

    # remove first and last timestamp
    obsdf = obsdf.iloc[1:-1]
    modeldf = modeldf.sapflux_scaled.isel(time=np.arange(1, len(modeldf.time) - 1))

    not_nans = ~obsdf[ex_settings["obsvar"]].isna()
    obsdf_not_nans = obsdf[ex_settings["obsvar"]].loc[not_nans]
    modeldf_not_nans = modeldf.data[not_nans]

    return modeldf_not_nans, obsdf_not_nans


def scale_sapflux(sapflux, dz, mean_crown_area_sp, total_crown_area_sp, plot_area):
    """Scales sapflux from FETCH output (in kg s-1) to W m-2"""
    scaled_sapflux = sapflux * 2440000 / mean_crown_area_sp * total_crown_area_sp / plot_area
    return scaled_sapflux


def scale_transpiration(trans, dz, mean_crown_area_sp, total_crown_area_sp, plot_area):
    """Scales transpiration from FETCH output (in m H20 m-2crown m-1stem s-1) to W m-2"""
    scaled_trans = (trans * 1000 * dz * 2440000 * total_crown_area_sp / plot_area).sum(
        dim="z", skipna=True
    )
    return scaled_trans


class Fetch3Wrapper(BaseWrapper):
    _processes = []

    def __init__(self, ex_settings, model_settings, experiment_dir):
        self.ex_settings = ex_settings
        self.model_settings = model_settings
        self.experiment_dir = experiment_dir

    def run_model(self, trial: Trial):

        trial_dir = make_trial_dir(self.experiment_dir, trial.index)

        config_dir = write_configs(trial_dir, trial.arm.parameters, self.model_settings)

        model_dir = self.ex_settings["model_dir"]

        # with cd_and_cd_back(model_dir):
        os.chdir(model_dir)

        cmd = (
            f"python main.py --config_path {config_dir} --data_path"
            f" {self.ex_settings['data_path']} --output_path {trial_dir}"
        )

        args = cmd.split()
        popen = subprocess.Popen(args, stdout=subprocess.PIPE, universal_newlines=True)
        self._processes.append(popen)

    def set_trial_status(self, trial: Trial) -> None:
        """ "Get status of the job by a given ID. For simplicity of the example,
        return an Ax `TrialStatus`.
        """
        log_file = get_trial_dir(self.experiment_dir, trial.index) / "fetch3.log"

        if log_file.exists():
            with open(log_file, "r") as f:
                contents = f.read()
            if "Error completing Run! Reason:" in contents:
                trial.mark_failed()
            elif "run complete" in contents:
                trial.mark_completed()

    def fetch_trial_data(self, trial: Trial, *args, **kwargs):

        modelfile = (
            get_trial_dir(self.experiment_dir, trial.index) / self.ex_settings["output_fname"]
        )

        y_pred, y_true = get_model_obs(
            modelfile,
            self.ex_settings["obsfile"],
            self.ex_settings,
            self.model_settings,
            trial.arm.parameters,
        )
        return dict(y_pred=y_pred, y_true=y_true)


def exit_handler():
    for process in Fetch3Wrapper._processes:
        process.kill()


atexit.register(exit_handler)
